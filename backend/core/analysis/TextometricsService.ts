/**
 * TextometricsService - Analyse statistique du texte et textom√©trie
 *
 * Fournit des statistiques lexicales d√©taill√©es :
 * - Comptages de base (mots, vocabulaire, phrases)
 * - Fr√©quence des mots (hors stopwords)
 * - N-grammes fr√©quents (bigrammes, trigrammes)
 * - Richesse lexicale
 */

export interface TextStatistics {
  // Comptages de base
  totalWords: number;
  uniqueWords: number;
  totalWordsWithStopwords: number;
  vocabularySize: number;
  lexicalRichness: number; // ratio uniqueWords / totalWords

  // Fr√©quences
  topWords: Array<{ word: string; count: number; frequency: number }>;
  topBigrams: Array<{ ngram: string; count: number }>;
  topTrigrams: Array<{ ngram: string; count: number }>;

  // Distribution
  wordFrequencyDistribution: Map<number, number>; // fr√©quence -> nb de mots avec cette fr√©quence
}

export interface CorpusTextStatistics extends TextStatistics {
  totalDocuments: number;
  averageWordsPerDocument: number;
  averageVocabularyPerDocument: number;
}

export interface DocumentTextStatistics extends TextStatistics {
  documentId: string;
  characteristicWords: Array<{ word: string; tfIdf: number }>; // Mots caract√©ristiques (TF-IDF)
}

interface WordFrequency {
  [word: string]: number;
}

/**
 * Service d'analyse textom√©trique
 */
export class TextometricsService {
  // Stopwords fran√ßais et anglais
  private readonly stopwords: Set<string>;

  constructor() {
    this.stopwords = new Set([
      // Stopwords fran√ßais
      'le',
      'la',
      'les',
      'un',
      'une',
      'des',
      'de',
      'du',
      'd',
      'et',
      'ou',
      'mais',
      'donc',
      'car',
      'pour',
      'dans',
      'sur',
      '√†',
      'au',
      'aux',
      'avec',
      'par',
      'ce',
      'qui',
      'que',
      'quoi',
      'dont',
      'il',
      'elle',
      'on',
      'nous',
      'vous',
      'ils',
      'elles',
      'cette',
      'ces',
      'son',
      'sa',
      'ses',
      'leur',
      'leurs',
      'mon',
      'ma',
      'mes',
      'ton',
      'ta',
      'tes',
      'notre',
      'votre',
      'se',
      's',
      'si',
      'ne',
      'ni',
      'pas',
      'plus',
      'sans',
      'y',
      'en',
      '√™tre',
      'avoir',
      'faire',
      'dit',
      'peut',
      'sont',
      '√©t√©',
      '√©tait',
      'est',
      'ai',
      'as',
      'avons',
      'avez',
      'ont',
      'suis',
      'es',
      'sommes',
      '√™tes',
      // Stopwords anglais
      'the',
      'a',
      'an',
      'and',
      'or',
      'but',
      'in',
      'on',
      'at',
      'to',
      'for',
      'of',
      'with',
      'by',
      'from',
      'as',
      'is',
      'was',
      'are',
      'were',
      'been',
      'be',
      'have',
      'has',
      'had',
      'do',
      'does',
      'did',
      'will',
      'would',
      'could',
      'should',
      'may',
      'might',
      'can',
      'this',
      'that',
      'these',
      'those',
      'it',
      'its',
      'he',
      'she',
      'they',
      'we',
      'you',
      'i',
      'me',
      'my',
      'your',
      'his',
      'her',
      'their',
      'our',
      'which',
      'who',
      'whom',
      'whose',
      'what',
      'where',
      'when',
      'why',
      'how',
      'not',
      'no',
      'nor',
      'so',
      'than',
      'too',
      'very',
      'also',
      'only',
      'just',
    ]);
  }

  /**
   * Tokenize le texte en mots
   * @param text Texte brut
   * @returns Liste de mots (lowercase, nettoy√©s)
   */
  private tokenize(text: string): string[] {
    // Supprimer les URLs et DOIs avant la tokenisation
    let cleanedText = text
      // Supprimer les URLs (http, https, ftp)
      .replace(/(?:https?|ftp):\/\/[^\s]+/gi, ' ')
      // Supprimer les DOIs (format doi:10.xxxx ou https://doi.org/10.xxxx)
      .replace(/\b(?:doi[:\s]*)?10\.\d{4,}(?:\.\d+)*\/[^\s]+/gi, ' ')
      // Supprimer les emails
      .replace(/[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}/g, ' ');

    // Nettoyer et normaliser le texte
    const normalized = cleanedText
      .toLowerCase()
      // Remplacer les apostrophes typographiques par des apostrophes simples
      .replace(/['']/g, "'")
      // Garder uniquement les lettres, chiffres, espaces, apostrophes et traits d'union
      .replace(/[^a-z√†√¢√§√¶√ß√©√®√™√´√Ø√Æ√¥≈ì√π√ª√º0-9\s'\-]/g, ' ')
      // Normaliser les espaces multiples
      .replace(/\s+/g, ' ')
      .trim();

    // S√©parer en mots
    const words = normalized.split(/\s+/).filter((word) => {
      // Filtrer les mots vides et trop courts
      if (word.length < 2 || this.stopwords.has(word)) {
        return false;
      }
      // Filtrer les fragments d'URLs/DOIs qui pourraient rester
      if (this.isUrlOrDoiFragment(word)) {
        return false;
      }
      return true;
    });

    return words;
  }

  /**
   * V√©rifie si un mot est un fragment d'URL ou de DOI
   */
  private isUrlOrDoiFragment(word: string): boolean {
    // Mots typiques des URLs et DOIs √† filtrer
    const urlDoiPatterns = [
      /^https?$/,
      /^www$/,
      /^ftp$/,
      /^doi$/,
      /^org$/,
      /^com$/,
      /^net$/,
      /^edu$/,
      /^gov$/,
      /^io$/,
      /^fr$/,
      /^de$/,
      /^uk$/,
      /^pdf$/,
      /^html$/,
      /^htm$/,
      /^php$/,
      /^aspx?$/,
      /^jsp$/,
      /^\d{4,}$/, // S√©quences de chiffres (typiques des DOIs)
      /^[a-z]\d+$/, // Lettres suivies de chiffres (ex: s12345)
      /^\d+[a-z]+$/, // Chiffres suivis de lettres
    ];

    return urlDoiPatterns.some(pattern => pattern.test(word));
  }

  /**
   * Tokenize en gardant les stopwords (pour calcul du total avec stopwords)
   */
  private tokenizeWithStopwords(text: string): string[] {
    const normalized = text
      .toLowerCase()
      .replace(/['']/g, "'")
      .replace(/[^a-z√†√¢√§√¶√ß√©√®√™√´√Ø√Æ√¥≈ì√π√ª√º0-9\s'\-]/g, ' ')
      .replace(/\s+/g, ' ')
      .trim();

    return normalized.split(/\s+/).filter((word) => word.length >= 1);
  }

  /**
   * Calcule la fr√©quence des mots
   */
  private calculateWordFrequency(words: string[]): WordFrequency {
    const frequency: WordFrequency = {};

    for (const word of words) {
      frequency[word] = (frequency[word] || 0) + 1;
    }

    return frequency;
  }

  /**
   * Extrait les n-grammes depuis une liste de mots
   * @param words Liste de mots
   * @param n Taille du n-gramme (2 = bigramme, 3 = trigramme)
   * @returns Fr√©quence des n-grammes
   */
  private extractNgrams(words: string[], n: number): WordFrequency {
    const ngrams: WordFrequency = {};

    for (let i = 0; i <= words.length - n; i++) {
      const ngram = words.slice(i, i + n).join(' ');
      ngrams[ngram] = (ngrams[ngram] || 0) + 1;
    }

    return ngrams;
  }

  /**
   * Calcule la distribution de fr√©quence (combien de mots apparaissent 1 fois, 2 fois, etc.)
   */
  private calculateFrequencyDistribution(frequency: WordFrequency): Map<number, number> {
    const distribution = new Map<number, number>();

    for (const count of Object.values(frequency)) {
      distribution.set(count, (distribution.get(count) || 0) + 1);
    }

    return distribution;
  }

  /**
   * Analyse un texte unique
   * @param text Texte √† analyser
   * @param topN Nombre de mots/n-grammes les plus fr√©quents √† retourner
   * @returns Statistiques textuelles
   */
  analyzeText(text: string, topN: number = 50): TextStatistics {
    console.log(`üìä [TextometricsService] analyzeText - input text length: ${text.length} characters`);

    // Tokenize
    const words = this.tokenize(text);
    const wordsWithStopwords = this.tokenizeWithStopwords(text);

    console.log(`üìä [TextometricsService] Tokenized: ${words.length} words (without stopwords), ${wordsWithStopwords.length} words (with stopwords)`);

    // Fr√©quence des mots
    const wordFrequency = this.calculateWordFrequency(words);

    // Trier par fr√©quence d√©croissante
    const sortedWords = Object.entries(wordFrequency)
      .sort(([, countA], [, countB]) => countB - countA)
      .slice(0, topN);

    const totalWords = words.length;
    const topWords = sortedWords.map(([word, count]) => ({
      word,
      count,
      frequency: count / totalWords,
    }));

    // N-grammes
    const bigramFrequency = this.extractNgrams(words, 2);
    const trigramFrequency = this.extractNgrams(words, 3);

    const topBigrams = Object.entries(bigramFrequency)
      .sort(([, countA], [, countB]) => countB - countA)
      .slice(0, topN)
      .map(([ngram, count]) => ({ ngram, count }));

    const topTrigrams = Object.entries(trigramFrequency)
      .sort(([, countA], [, countB]) => countB - countA)
      .slice(0, topN)
      .map(([ngram, count]) => ({ ngram, count }));

    // Distribution de fr√©quence
    const wordFrequencyDistribution = this.calculateFrequencyDistribution(wordFrequency);

    return {
      totalWords,
      uniqueWords: Object.keys(wordFrequency).length,
      totalWordsWithStopwords: wordsWithStopwords.length,
      vocabularySize: Object.keys(wordFrequency).length,
      lexicalRichness: Object.keys(wordFrequency).length / totalWords || 0,
      topWords,
      topBigrams,
      topTrigrams,
      wordFrequencyDistribution,
    };
  }

  /**
   * Analyse un corpus complet (plusieurs documents)
   * @param documents Liste de documents avec leur texte
   * @param topN Nombre de mots/n-grammes les plus fr√©quents √† retourner
   * @returns Statistiques du corpus
   */
  analyzeCorpus(
    documents: Array<{ id: string; text: string }>,
    topN: number = 50
  ): CorpusTextStatistics {
    console.log(`üìä [TextometricsService] Analyzing corpus with ${documents.length} documents`);

    // Concat√©ner tous les textes
    const fullCorpusText = documents.map((doc) => doc.text).join(' ');
    console.log(`üìä [TextometricsService] Full corpus text length: ${fullCorpusText.length} characters`);

    // Analyser le corpus complet
    const corpusStats = this.analyzeText(fullCorpusText, topN);

    // Calculer les moyennes par document
    let totalWordsAllDocs = 0;
    let totalVocabularyAllDocs = 0;

    for (const doc of documents) {
      const docStats = this.analyzeText(doc.text, topN);
      totalWordsAllDocs += docStats.totalWords;
      totalVocabularyAllDocs += docStats.vocabularySize;
    }

    return {
      ...corpusStats,
      totalDocuments: documents.length,
      averageWordsPerDocument: totalWordsAllDocs / documents.length || 0,
      averageVocabularyPerDocument: totalVocabularyAllDocs / documents.length || 0,
    };
  }

  /**
   * Analyse un document sp√©cifique avec calcul de TF-IDF pour les mots caract√©ristiques
   * @param documentText Texte du document
   * @param corpusDocuments Tous les documents du corpus (pour TF-IDF)
   * @param topN Nombre de mots/n-grammes les plus fr√©quents
   * @returns Statistiques du document avec mots caract√©ristiques
   */
  analyzeDocument(
    documentId: string,
    documentText: string,
    corpusDocuments: Array<{ id: string; text: string }>,
    topN: number = 50
  ): DocumentTextStatistics {
    // Analyser le document
    const docStats = this.analyzeText(documentText, topN);

    // Calculer TF-IDF pour les mots caract√©ristiques
    const characteristicWords = this.calculateTfIdf(documentText, corpusDocuments, topN);

    return {
      ...docStats,
      documentId,
      characteristicWords,
    };
  }

  /**
   * Calcule le TF-IDF pour trouver les mots caract√©ristiques d'un document
   * @param documentText Texte du document cible
   * @param corpusDocuments Tous les documents du corpus
   * @param topN Nombre de mots caract√©ristiques √† retourner
   * @returns Liste des mots avec leur score TF-IDF
   */
  private calculateTfIdf(
    documentText: string,
    corpusDocuments: Array<{ id: string; text: string }>,
    topN: number
  ): Array<{ word: string; tfIdf: number }> {
    const docWords = this.tokenize(documentText);
    const docWordFreq = this.calculateWordFrequency(docWords);
    const docWordCount = docWords.length;

    // Calculer IDF pour chaque mot
    const idfScores: { [word: string]: number } = {};
    const totalDocs = corpusDocuments.length;

    for (const word of Object.keys(docWordFreq)) {
      // Compter dans combien de documents ce mot appara√Æt
      let docsWithWord = 0;
      for (const doc of corpusDocuments) {
        const words = this.tokenize(doc.text);
        if (words.includes(word)) {
          docsWithWord++;
        }
      }

      // IDF = log(N / df)
      idfScores[word] = Math.log(totalDocs / (docsWithWord || 1));
    }

    // Calculer TF-IDF
    const tfIdfScores = Object.entries(docWordFreq).map(([word, count]) => {
      const tf = count / docWordCount;
      const idf = idfScores[word];
      const tfIdf = tf * idf;

      return { word, tfIdf };
    });

    // Trier par score TF-IDF d√©croissant
    tfIdfScores.sort((a, b) => b.tfIdf - a.tfIdf);

    return tfIdfScores.slice(0, topN);
  }

  /**
   * Ajoute des stopwords personnalis√©s
   */
  addStopwords(words: string[]): void {
    for (const word of words) {
      this.stopwords.add(word.toLowerCase());
    }
  }

  /**
   * Supprime des stopwords
   */
  removeStopwords(words: string[]): void {
    for (const word of words) {
      this.stopwords.delete(word.toLowerCase());
    }
  }

  /**
   * Retourne la liste des stopwords actuels
   */
  getStopwords(): string[] {
    return Array.from(this.stopwords).sort();
  }
}
