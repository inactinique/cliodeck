// @ts-nocheck
import { LRUCache } from 'lru-cache';
import { pdfService } from './pdf-service.js';
import { BrowserWindow } from 'electron';
import { historyService } from './history-service.js';
import { ContextCompressor } from '../../../backend/core/rag/ContextCompressor.js';
import { getSystemPrompt } from '../../../backend/core/llm/SystemPrompts.js';

// Options enrichies pour le RAG
interface EnrichedRAGOptions {
  context?: boolean;              // Activer le RAG
  useGraphContext?: boolean;      // Utiliser le graphe de connaissances
  includeSummaries?: boolean;     // Utiliser r√©sum√©s au lieu de chunks
  topK?: number;                  // Nombre de r√©sultats de recherche
  additionalGraphDocs?: number;   // Nombre de documents li√©s √† inclure
  window?: BrowserWindow;         // Fen√™tre pour streaming

  // Source type selection (primary = Tropy archives, secondary = PDFs, both = all)
  sourceType?: 'secondary' | 'primary' | 'both';

  // Document filtering (Issue #16: filter RAG search by specific document IDs)
  documentIds?: string[];         // Document IDs to search in (if empty, search all)

  // Collection filtering (filter RAG search by Zotero collections)
  collectionKeys?: string[];      // Zotero collection keys to filter by

  // Provider selection
  provider?: 'ollama' | 'embedded' | 'auto';  // LLM provider to use

  // Per-query parameters
  model?: string;                 // Override chat model
  timeout?: number;               // Timeout in milliseconds
  numCtx?: number;                // Context window size in tokens (Ollama num_ctx)
  temperature?: number;           // LLM temperature
  top_p?: number;                 // LLM top_p
  top_k?: number;                 // LLM top_k
  repeat_penalty?: number;        // LLM repeat penalty

  // System prompt configuration (Phase 2.3)
  systemPromptLanguage?: 'fr' | 'en';    // Language for default prompt
  useCustomSystemPrompt?: boolean;       // Use custom prompt
  customSystemPrompt?: string;           // Custom system prompt text

  // Context compression
  enableContextCompression?: boolean;    // Enable context compression (default: true)

  // Mode tracking
  modeId?: string;                      // Active mode ID for history logging
  noSystemPrompt?: boolean;             // Free mode: skip system prompt entirely
}

// Type pour l'explication du RAG (Explainable AI)
export interface RAGExplanationContext {
  // Recherche
  search: {
    query: string;
    totalResults: number;
    searchDurationMs: number;
    cacheHit: boolean;
    sourceType: 'primary' | 'secondary' | 'both';
    documents: Array<{
      title: string;
      similarity: number;
      sourceType: 'primary' | 'secondary';
      chunkCount: number;
    }>;
    boosting?: {
      exactMatchCount: number;
      keywords: string[];
    };
  };
  // Compression
  compression?: {
    enabled: boolean;
    originalChunks: number;
    finalChunks: number;
    originalSize: number;
    finalSize: number;
    reductionPercent: number;
    strategy?: string;
  };
  // Graphe de connaissances
  graph?: {
    enabled: boolean;
    relatedDocsFound: number;
    documentTitles: string[];
  };
  // Configuration LLM
  llm: {
    provider: string;
    model: string;
    contextWindow: number;
    temperature: number;
    promptSize: number;
  };
  // Timing
  timing: {
    searchMs: number;
    compressionMs?: number;
    generationMs: number;
    totalMs: number;
  };
}

// Fonction utilitaire pour hasher une cha√Æne (identifier les questions identiques)
function hashString(str: string): string {
  let hash = 0;
  const normalized = str.toLowerCase().trim();
  for (let i = 0; i < normalized.length; i++) {
    hash = ((hash << 5) - hash) + normalized.charCodeAt(i);
    hash |= 0; // Convert to 32bit integer
  }
  return hash.toString(16);
}

// Fonction utilitaire pour calculer la similarit√© cosinus entre deux vecteurs
function cosineSimilarity(a: Float32Array, b: Float32Array): number {
  if (a.length !== b.length) return 0;

  let dotProduct = 0;
  let normA = 0;
  let normB = 0;

  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i];
    normA += a[i] * a[i];
    normB += b[i] * b[i];
  }

  const magnitude = Math.sqrt(normA) * Math.sqrt(normB);
  if (magnitude === 0) return 0;

  return dotProduct / magnitude;
}

class ChatService {
  private currentStream: any = null;
  private compressor: ContextCompressor = new ContextCompressor();

  // LRU Cache for RAG search results (cache identical queries)
  // üöÄ OPTIMIZED: Increased capacity (100‚Üí200) and TTL (10‚Üí30 minutes)
  private ragCache = new LRUCache<string, any[]>({
    max: 200, // Store up to 200 different queries
    ttl: 1000 * 60 * 30, // 30 minutes TTL
    updateAgeOnGet: true, // Refresh TTL on access
  });

  /**
   * Convertit les r√©sultats de recherche en utilisant les r√©sum√©s au lieu des chunks
   * Si les r√©sum√©s ne sont pas disponibles, retourne les chunks originaux
   */
  private convertChunksToSummaries(searchResults: any[]): any[] {
    const summaryResults: any[] = [];
    const seenDocuments = new Set<string>();
    let summariesFound = 0;

    for (const result of searchResults) {
      const docId = result.document.id;

      // √âviter les doublons (un r√©sum√© par document)
      if (seenDocuments.has(docId)) {
        continue;
      }

      if (result.document.summary) {
        seenDocuments.add(docId);
        summariesFound++;
        summaryResults.push({
          document: result.document,
          chunk: {
            content: result.document.summary,
            pageNumber: 1
          },
          similarity: result.similarity
        });
      }
    }

    // Fallback: if no summaries available, return original chunks
    if (summaryResults.length === 0 && searchResults.length > 0) {
      console.warn('‚ö†Ô∏è  No document summaries found. Falling back to original chunks.');
      console.warn('‚ö†Ô∏è  To use summaries, re-index your documents with summary generation enabled.');
      return searchResults;
    }

    console.log(`üìù Using summaries: ${summariesFound} documents with summaries found`);
    return summaryResults;
  }

  /**
   * R√©cup√®re les documents li√©s via le graphe de connaissances
   */
  private async getRelatedDocumentsFromGraph(
    documentIds: string[],
    limit: number = 3
  ): Promise<Set<string>> {
    const relatedDocs = new Set<string>();
    const vectorStore = pdfService.getVectorStore();

    if (!vectorStore) {
      return relatedDocs;
    }

    for (const docId of documentIds) {
      // R√©cup√©rer documents cit√©s par ce document
      const citedDocs = vectorStore.getDocumentsCitedBy(docId);
      citedDocs.slice(0, Math.ceil(limit / 2)).forEach(id => relatedDocs.add(id));

      // R√©cup√©rer documents qui citent ce document
      const citingDocs = vectorStore.getDocumentsCiting(docId);
      citingDocs.slice(0, Math.ceil(limit / 2)).forEach(id => relatedDocs.add(id));

      // R√©cup√©rer documents similaires
      const similarDocs = vectorStore.getSimilarDocuments(docId, 0.7, limit);
      similarDocs.forEach(({ documentId }) => relatedDocs.add(documentId));
    }

    // Retirer les documents originaux
    documentIds.forEach(id => relatedDocs.delete(id));

    return relatedDocs;
  }

  async sendMessage(
    message: string,
    options: EnrichedRAGOptions = {}
  ): Promise<{ response: string; ragUsed: boolean; sourcesCount: number; explanation?: RAGExplanationContext }> {
    const startTime = Date.now();
    const queryHash = hashString(message);

    // M√©tadonn√©es pour l'explication (Explainable AI)
    let explanationContext: RAGExplanationContext | undefined;
    let searchDurationMs = 0;
    let compressionDurationMs = 0;
    let cacheHit = false;

    try {
      // Obtenir le LLM Provider Manager (g√®re Ollama + mod√®le embarqu√©)
      const llmProviderManager = pdfService.getLLMProviderManager();
      if (!llmProviderManager) {
        throw new Error('LLM Provider Manager not initialized. Load a project first.');
      }

      // Appliquer le provider s√©lectionn√© par l'utilisateur (from RAG settings)
      if (options.provider) {
        console.log(`üîß [CHAT] Setting provider preference: ${options.provider}`);
        llmProviderManager.setProvider(options.provider);
      }

      // V√©rifier qu'au moins un provider est disponible
      const activeProvider = await llmProviderManager.getActiveProvider();
      if (!activeProvider) {
        throw new Error(
          'Aucun LLM disponible.\n\n' +
          'Options:\n' +
          '1. Installez et d√©marrez Ollama (https://ollama.ai)\n' +
          '2. T√©l√©chargez le mod√®le embarqu√© dans Param√®tres ‚Üí LLM'
        );
      }

      console.log(`ü§ñ [CHAT] Using LLM provider: ${llmProviderManager.getActiveProviderName()}`);

      let fullResponse = '';
      let searchResults: any[] = [];
      let relatedDocuments: any[] = [];

      // Si contexte activ√©, rechercher dans les documents
      if (options.context) {
        const searchStart = Date.now();

        // üöÄ FEEDBACK: Send status update - searching
        if (options.window) {
          options.window.webContents.send('chat:status', {
            stage: 'searching',
            message: 'üîç Recherche dans les documents...',
          });
        }

        console.log('üîç [RAG DETAILED DEBUG] Starting RAG search:', {
          query: message.substring(0, 100) + (message.length > 100 ? '...' : ''),
          queryLength: message.length,
          queryHash: queryHash,
          topK: options.topK,
          useGraphContext: options.useGraphContext,
          includeSummaries: options.includeSummaries,
          timestamp: new Date().toISOString(),
        });

        // Check cache first (identical queries = instant results)
        // Include collection filter, source type and document IDs in cache key to avoid mixing results
        const collectionSuffix = options.collectionKeys?.length ? `-coll:${options.collectionKeys.sort().join(',')}` : '';
        const sourceTypeSuffix = options.sourceType ? `-src:${options.sourceType}` : '-src:both';
        const documentIdsSuffix = options.documentIds?.length ? `-docs:${options.documentIds.sort().join(',')}` : '';
        const cacheKey = `${queryHash}-${options.topK || 5}${collectionSuffix}${sourceTypeSuffix}${documentIdsSuffix}`;
        const cachedResults = this.ragCache.get(cacheKey);

        if (cachedResults) {
          console.log(`üíæ Cache HIT for query hash ${queryHash} (saved ${Date.now() - searchStart}ms)`);
          searchResults = cachedResults;
          cacheHit = true;
        } else {
          console.log(`üîç Cache MISS for query hash ${queryHash}, performing search...`);
          searchResults = await pdfService.search(message, {
            topK: options.topK,
            collectionKeys: options.collectionKeys,
            sourceType: options.sourceType,
            documentIds: options.documentIds, // Issue #16: filter by specific documents
          });

          // Store in cache for future identical queries
          this.ragCache.set(cacheKey, searchResults);
          console.log(`üíæ Cached ${searchResults.length} results for query hash ${queryHash}`);
        }
        searchDurationMs = Date.now() - searchStart;

        // Filter out results with null documents (orphaned chunks)
        searchResults = searchResults.filter(r => r.document !== null);

        console.log('üîç [RAG DETAILED DEBUG] Search completed:', {
          queryHash: queryHash,
          resultsCount: searchResults.length,
          searchDuration: `${searchDurationMs}ms`,
          topSimilarities: searchResults.slice(0, 5).map(r => r.similarity.toFixed(4)),
          chunkIds: searchResults.slice(0, 3).map(r => r.chunk.id),
          documentTitles: searchResults.slice(0, 3).map(r => r.document?.title || 'Unknown'),
        });

        if (searchResults.length > 0) {
          console.log(`üìö Using ${searchResults.length} context chunks for RAG`);

          // üöÄ FEEDBACK: Send status update - found sources
          if (options.window) {
            options.window.webContents.send('chat:status', {
              stage: 'found',
              message: `üìö ${searchResults.length} sources trouv√©es`,
            });
          }

          // Log first result for debugging
          console.log('üîç [RAG DEBUG] First result:', {
            document: searchResults[0].document?.title || 'Unknown',
            similarity: searchResults[0].similarity,
            chunkLength: searchResults[0].chunk.content.length
          });

          // Si graphe activ√©, r√©cup√©rer documents li√©s
          if (options.useGraphContext) {
            const uniqueDocIds = [...new Set(searchResults.map(r => r.document.id))];
            const relatedDocIds = await this.getRelatedDocumentsFromGraph(
              uniqueDocIds,
              options.additionalGraphDocs || 3
            );

            console.log(`üîó Found ${relatedDocIds.size} related documents via graph`);

            // R√©cup√©rer les documents complets
            const vectorStore = pdfService.getVectorStore();
            if (vectorStore && relatedDocIds.size > 0) {
              relatedDocuments = Array.from(relatedDocIds)
                .map(id => vectorStore.getDocument(id))
                .filter(doc => doc !== null);
            }
          }

          // Si r√©sum√©s activ√©s, utiliser r√©sum√©s au lieu de chunks
          if (options.includeSummaries) {
            console.log('üìù Using document summaries instead of chunks');
            // Remplacer chunks par r√©sum√©s
            searchResults = this.convertChunksToSummaries(searchResults);
            if (relatedDocuments.length > 0) {
              // Ajouter r√©sum√©s des documents li√©s avec vraie similarit√©
              const ollamaClient = pdfService.getOllamaClient();
              if (ollamaClient) {
                try {
                  // G√©n√©rer l'embedding de la requ√™te
                  const queryEmbedding = await ollamaClient.generateEmbedding(message);
                  console.log(`üîó Computing real similarity for ${relatedDocuments.length} graph-related documents`);

                  for (const doc of relatedDocuments) {
                    if (doc.summary) {
                      try {
                        // G√©n√©rer l'embedding du r√©sum√© et calculer la vraie similarit√©
                        const summaryEmbedding = await ollamaClient.generateEmbedding(doc.summary);
                        const realSimilarity = cosineSimilarity(queryEmbedding, summaryEmbedding);
                        console.log(`   üìÑ ${doc.title}: similarity = ${(realSimilarity * 100).toFixed(1)}%`);

                        searchResults.push({
                          document: doc,
                          chunk: { content: doc.summary, pageNumber: 1 },
                          similarity: realSimilarity,
                          isRelatedDoc: true
                        });
                      } catch (embError) {
                        console.warn(`‚ö†Ô∏è Failed to compute similarity for ${doc.title}:`, embError);
                        // Fallback: utiliser 0.5 au lieu de 0.7 (indique incertitude)
                        searchResults.push({
                          document: doc,
                          chunk: { content: doc.summary, pageNumber: 1 },
                          similarity: 0.5,
                          isRelatedDoc: true
                        });
                      }
                    }
                  }
                } catch (queryEmbError) {
                  console.warn('‚ö†Ô∏è Failed to generate query embedding for graph docs:', queryEmbError);
                  // Fallback: ajouter sans similarit√© calcul√©e
                  relatedDocuments.forEach(doc => {
                    if (doc.summary) {
                      searchResults.push({
                        document: doc,
                        chunk: { content: doc.summary, pageNumber: 1 },
                        similarity: 0.5, // Score indiquant incertitude
                        isRelatedDoc: true
                      });
                    }
                  });
                }
              } else {
                // Pas d'OllamaClient, utiliser le fallback
                console.warn('‚ö†Ô∏è No OllamaClient available for similarity computation');
                relatedDocuments.forEach(doc => {
                  if (doc.summary) {
                    searchResults.push({
                      document: doc,
                      chunk: { content: doc.summary, pageNumber: 1 },
                      similarity: 0.5, // Score indiquant incertitude
                      isRelatedDoc: true
                    });
                  }
                });
              }
            }
          }
        }
      }

      // Apply intelligent compression to context chunks (if enabled)
      const compressionEnabled = options.enableContextCompression !== false; // Default: true
      let compressionStats: RAGExplanationContext['compression'] | undefined;

      if (searchResults.length > 0 && compressionEnabled) {
        const compressionStart = Date.now();
        const preCompressionSize = searchResults.reduce((sum, r) => sum + r.chunk.content.length, 0);
        const preCompressionChunks = searchResults.length;
        console.log(`üóúÔ∏è  [COMPRESSION] Pre-compression context size: ${preCompressionSize} chars (${searchResults.length} chunks)`);

        // Convert search results to compressor format
        const chunksForCompression = searchResults.map(r => ({
          content: r.chunk.content,
          documentId: r.document.id,
          documentTitle: r.document.title,
          pageNumber: r.chunk.pageNumber,
          similarity: r.similarity,
        }));

        // Compress with 20k char target
        const compressionResult = this.compressor.compress(chunksForCompression, message, 20000);

        // Convert back to search result format
        searchResults = compressionResult.chunks.map(chunk => ({
          document: {
            id: chunk.documentId,
            title: chunk.documentTitle,
          },
          chunk: {
            content: chunk.content,
            pageNumber: chunk.pageNumber,
          },
          similarity: chunk.similarity,
        }));

        compressionDurationMs = Date.now() - compressionStart;

        // Capturer les stats de compression pour l'explication
        compressionStats = {
          enabled: true,
          originalChunks: compressionResult.stats.originalChunks,
          finalChunks: compressionResult.stats.compressedChunks,
          originalSize: compressionResult.stats.originalSize,
          finalSize: compressionResult.stats.compressedSize,
          reductionPercent: compressionResult.stats.reductionPercent,
          strategy: compressionResult.stats.strategy,
        };

        console.log(`‚úÖ [COMPRESSION] Final stats:`, {
          strategy: compressionResult.stats.strategy,
          originalChunks: compressionResult.stats.originalChunks,
          compressedChunks: compressionResult.stats.compressedChunks,
          originalSize: compressionResult.stats.originalSize,
          compressedSize: compressionResult.stats.compressedSize,
          reduction: `${compressionResult.stats.reductionPercent.toFixed(1)}%`,
        });
      } else if (searchResults.length > 0 && !compressionEnabled) {
        const contextSize = searchResults.reduce((sum, r) => sum + r.chunk.content.length, 0);
        compressionStats = {
          enabled: false,
          originalChunks: searchResults.length,
          finalChunks: searchResults.length,
          originalSize: contextSize,
          finalSize: contextSize,
          reductionPercent: 0,
        };
        console.log(`‚è≠Ô∏è  [COMPRESSION] Skipped (disabled in settings). Context size: ${contextSize} chars (${searchResults.length} chunks)`);
      }

      // R√©cup√©rer le contexte du projet
      const projectContext = pdfService.getProjectContext();

      // Build system prompt based on configuration (Phase 2.3 + Modes)
      let systemPrompt: string;
      const systemPromptLanguage = options.systemPromptLanguage || 'fr';
      const useCustomPrompt = options.useCustomSystemPrompt || false;
      const customPrompt = options.customSystemPrompt;
      if (options.noSystemPrompt) {
        // Free mode: no system prompt
        systemPrompt = '';
      } else {
        systemPrompt = getSystemPrompt(systemPromptLanguage, useCustomPrompt, customPrompt);
      }

      console.log('ü§ñ [SYSTEM PROMPT] Configuration:', {
        language: systemPromptLanguage,
        noSystemPrompt: options.noSystemPrompt || false,
        useCustom: useCustomPrompt,
        hasCustom: !!customPrompt,
        promptPreview: systemPrompt.substring(0, 100) + '...',
      });

      // Build generation options (commun aux deux cas)
      const generationOptions = {
        temperature: options.temperature,
        top_p: options.top_p,
        top_k: options.top_k,
        repeat_penalty: options.repeat_penalty,
        num_ctx: options.numCtx,  // Context window size for Ollama
      };

      // üöÄ FEEDBACK: Send status update - generating
      if (options.window) {
        options.window.webContents.send('chat:status', {
          stage: 'generating',
          message: '‚ú® G√©n√©ration de la r√©ponse...',
        });
      }

      // Track generation timing and prompt size for explanation
      const generationStart = Date.now();
      let promptSize = 0;

      // Stream la r√©ponse avec contexte RAG si disponible
      if (searchResults.length > 0) {
        // Calculate approximate prompt size (for explanation)
        const contextSize = searchResults.reduce((sum, r) => sum + r.chunk.content.length, 0);
        promptSize = message.length + contextSize + systemPrompt.length + (projectContext?.length || 0);

        console.log('‚úÖ [RAG DETAILED DEBUG] Generating response WITH context:', {
          queryHash: queryHash,
          contextsUsed: searchResults.length,
          avgSimilarity: (searchResults.reduce((sum, r) => sum + r.similarity, 0) / searchResults.length).toFixed(4),
          mode: 'RAG_WITH_SOURCES',
          projectContextLoaded: !!projectContext,
          provider: llmProviderManager.getActiveProviderName(),
          timeout: options.timeout || 600000,
        });

        // Utiliser LLMProviderManager pour la g√©n√©ration (Ollama ou embarqu√©)
        const generator = llmProviderManager.generateWithSources(
          message,
          searchResults,
          projectContext,
          {
            model: options.model,
            timeout: options.timeout,
            generationOptions,
            systemPrompt,
          }
        );
        this.currentStream = generator;

        for await (const chunk of generator) {
          fullResponse += chunk;
          // Envoyer le chunk au renderer si une fen√™tre est fournie
          if (options.window) {
            options.window.webContents.send('chat:stream', chunk);
          }
        }
      } else {
        console.warn('‚ö†Ô∏è  [RAG DETAILED DEBUG] No search results - generating response WITHOUT context');
        console.warn('‚ö†Ô∏è  [RAG DETAILED DEBUG] Fallback mode details:', {
          queryHash: queryHash,
          query: message.substring(0, 100),
          contextRequested: options.context,
          topK: options.topK,
          mode: 'FALLBACK_NO_CONTEXT',
          warning: 'This response will be GENERIC and NOT based on your documents!',
        });

        // Utiliser LLMProviderManager pour la g√©n√©ration sans sources
        const generator = llmProviderManager.generateWithoutSources(
          message,
          [],
          {
            model: options.model,
            timeout: options.timeout,
            generationOptions,
            systemPrompt,
          }
        );
        this.currentStream = generator;

        for await (const chunk of generator) {
          fullResponse += chunk;
          // Envoyer le chunk au renderer si une fen√™tre est fournie
          if (options.window) {
            options.window.webContents.send('chat:stream', chunk);
          }
        }
      }

      const totalDuration = Date.now() - startTime;

      console.log('‚úÖ [RAG DETAILED DEBUG] Chat response completed:', {
        queryHash: queryHash,
        responseLength: fullResponse.length,
        totalDuration: `${totalDuration}ms`,
        ragUsed: searchResults.length > 0,
        timestamp: new Date().toISOString(),
      });

      // Log chat messages and AI operation to history
      const hm = historyService.getHistoryManager();
      if (hm) {
        // Build query params for history
        const queryParams = {
          model: options.model || llmProviderManager.getActiveProviderName(),
          topK: options.topK,
          timeout: options.timeout || 600000,
          temperature: options.temperature,
          top_p: options.top_p,
          top_k: options.top_k,
          repeat_penalty: options.repeat_penalty,
          useGraphContext: options.useGraphContext || false,
          includeSummaries: options.includeSummaries || false,
          modeId: options.modeId || 'default-assistant',
        };

        // Log user message with query params
        hm.logChatMessage({
          role: 'user',
          content: message,
          queryParams,
        });

        // Log assistant response with sources
        const sources =
          searchResults.length > 0
            ? searchResults.map((r) => ({
                documentId: r.document?.id || '',
                documentTitle: r.document?.title || 'Unknown',
                author: r.document?.author || '',
                year: r.document?.year || 0,
                pageNumber: r.chunk.pageNumber,
                similarity: r.similarity,
                isRelatedDoc: r.isRelatedDoc || false,
              }))
            : undefined;

        hm.logChatMessage({
          role: 'assistant',
          content: fullResponse,
          sources,
          queryParams,
        });

        // Log RAG operation if context was used
        if (options.context && searchResults.length > 0) {
          hm.logAIOperation({
            operationType: 'rag_query',
            durationMs: totalDuration,
            inputText: message,
            inputMetadata: {
              topK: options.topK,
              useGraphContext: options.useGraphContext || false,
              includeSummaries: options.includeSummaries || false,
              sourcesFound: searchResults.length,
              relatedDocumentsFound: relatedDocuments.length,
            },
            modelName: llmProviderManager.getActiveProviderName(),
            modelParameters: {
              temperature: options.temperature || 0.1,
              provider: activeProvider,
            },
            outputText: fullResponse,
            outputMetadata: {
              sources: sources || [],
              responseLength: fullResponse.length,
            },
            success: true,
          });

          console.log(
            `üìù Logged RAG query: ${searchResults.length} sources, ${totalDuration}ms`
          );
        }
      }

      // Build explanation context (Explainable AI)
      const generationDurationMs = Date.now() - generationStart;
      if (options.context && searchResults.length > 0) {
        // Group results by document
        const documentMap = new Map<string, { title: string; similarity: number; sourceType: string; chunkCount: number }>();
        searchResults.forEach(r => {
          const docId = r.document?.id || 'unknown';
          const existing = documentMap.get(docId);
          if (existing) {
            existing.chunkCount++;
            existing.similarity = Math.max(existing.similarity, r.similarity);
          } else {
            documentMap.set(docId, {
              title: r.document?.title || 'Unknown',
              similarity: r.similarity,
              sourceType: r.sourceType || 'secondary',
              chunkCount: 1,
            });
          }
        });

        explanationContext = {
          search: {
            query: message,
            totalResults: searchResults.length,
            searchDurationMs,
            cacheHit,
            sourceType: options.sourceType || 'both',
            documents: Array.from(documentMap.values()).slice(0, 10) as any,
          },
          compression: compressionStats,
          graph: options.useGraphContext ? {
            enabled: true,
            relatedDocsFound: relatedDocuments.length,
            documentTitles: relatedDocuments.map(d => d.title || 'Unknown'),
          } : undefined,
          llm: {
            provider: llmProviderManager.getActiveProviderName(),
            model: llmProviderManager.getActiveModelName(),
            contextWindow: options.numCtx || 4096,
            temperature: options.temperature || 0.1,
            promptSize,
          },
          timing: {
            searchMs: searchDurationMs,
            compressionMs: compressionDurationMs > 0 ? compressionDurationMs : undefined,
            generationMs: generationDurationMs,
            totalMs: totalDuration,
          },
        };
      }

      return {
        response: fullResponse,
        ragUsed: searchResults.length > 0,
        sourcesCount: searchResults.length,
        explanation: explanationContext,
      };
    } catch (error: any) {
      console.error('‚ùå [RAG DETAILED DEBUG] Chat error:', {
        queryHash: queryHash,
        error: error.message,
        stack: error.stack,
        classified: error.classified, // If error was classified by OllamaClient
      });

      // üöÄ FEEDBACK: Send error status to renderer
      if (options.window) {
        options.window.webContents.send('chat:status', {
          stage: 'error',
          message: error.message || 'Une erreur est survenue',
        });
      }

      throw error;
    }
  }

  cancelCurrentStream() {
    if (this.currentStream) {
      // TODO: Impl√©menter cancel dans OllamaClient si n√©cessaire
      this.currentStream = null;
      console.log('‚ö†Ô∏è  Chat stream cancelled');
    }
  }
}

export const chatService = new ChatService();
